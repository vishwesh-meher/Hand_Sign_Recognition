{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7505 images belonging to 5 classes.\n",
      "Found 200 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "train_path = r'C:\\Users\\vishw\\Desktop\\ASL\\gesture\\train'\n",
    "test_path = r'C:\\Users\\vishw\\Desktop\\ASL\\gesture\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=14,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1,6 , figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(5,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "537/537 [==============================] - 17s 33ms/step - loss: 0.1950 - accuracy: 0.9777 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 5.7005e-04 - accuracy: 1.0000 - val_loss: 1.5106e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "537/537 [==============================] - 17s 33ms/step - loss: 3.8110e-04 - accuracy: 1.0000 - val_loss: 2.7219e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 3.0010e-04 - accuracy: 1.0000 - val_loss: 1.2992e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 2.6342e-04 - accuracy: 1.0000 - val_loss: 7.9082e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 2.3459e-04 - accuracy: 1.0000 - val_loss: 9.3899e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 2.1164e-04 - accuracy: 1.0000 - val_loss: 8.4960e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 1.9222e-04 - accuracy: 1.0000 - val_loss: 1.3204e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "537/537 [==============================] - 18s 33ms/step - loss: 1.7568e-04 - accuracy: 1.0000 - val_loss: 6.5330e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.00010888996621361002; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "#Once the model is fitted we save the model using model.save()  function.\n",
    "\n",
    "\n",
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "Vulcan Salute   I Hate You   Good Job   Vulcan Salute   Vulcan Salute   Good Job   High Five   I Hate You   Good Job   I Hate You   Vulcan Salute   High Five   Hello   Vulcan Salute   "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "Vulcan Salute   I Hate You   Good Job   Vulcan Salute   Vulcan Salute   Good Job   High Five   I Hate You   Good Job   I Hate You   Vulcan Salute   High Five   Hello   Vulcan Salute   "
     ]
    }
   ],
   "source": [
    "word_dict = {0:'Good Job',1:'Hello',2:'High Five',3:'I Hate You',4:'Vulcan Salute'}\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
